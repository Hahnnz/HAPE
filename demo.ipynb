{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import ann, Dense_resnet, mask_rcnn\n",
    "from scripts import tools, dataset\n",
    "from scripts.config import *\n",
    "from models.layers import *\n",
    "\n",
    "tools.etc.set_GPU('1')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask RCNN\n",
    "class InferenceConfig(mask_rcnn.Config):\n",
    "    NAME = \"coco\"\n",
    "    NUM_CLASSES = 1 + 80\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "Human_Detector = mask_rcnn.MaskRCNN(mode=\"inference\", config=config,model_dir='./snapshots/Mask_RCNN/')\n",
    "Human_Detector.load_weights('./snapshots/Mask_RCNN/mask_rcnn_coco.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "All_Graph = tf.Graph()\n",
    "with All_Graph.as_default():\n",
    "    num_joints=14\n",
    "    model_list=['Human_Joint_Pointer','Human_Pose_Estimator']\n",
    "        \n",
    "    with tf.variable_scope(model_list[0]):\n",
    "        \"\"\"\n",
    "        Human_Joint_Pointer = regressionnet_resnet.Regressionnet(data_shape=(128,128,3),num_joints=14,\n",
    "                                                                 gpu_memory_fraction=None, phase='inference')\n",
    "        \"\"\"\n",
    "        Human_Joint_Pointer = Dense_resnet.Regressionnet(data_shape=(128,128,3),num_joints=14,gpu_memory_fraction=None, phase='inference')\n",
    "    with tf.variable_scope(model_list[1]):\n",
    "        Human_Pose_Estimator = ann.ann(input_shape=28,output_shape=10)\n",
    "        \n",
    "    var_name_list = [[] for _ in range(len(model_list))]\n",
    "    var_dict_list = [dict() for _ in range(len(model_list))]\n",
    "    \n",
    "    for var in tf.global_variables():\n",
    "        var_name_list[model_list.index(var.name.split('/')[0])].append(var)\n",
    "        \n",
    "    for i in range(len(model_list)):\n",
    "        for var in var_name_list[i]:\n",
    "            var_dict_list[i].update({'/'.join(var.name.split('/')[1:]).replace(':0',''):\n",
    "                                     All_Graph.get_tensor_by_name(var.name)}) \n",
    "\n",
    "    saver_list = [tf.train.Saver(var_list=var_dict_list[i]) for i in range(len(model_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config, graph=All_Graph)\n",
    "\n",
    "saver_path = ['./snapshots/Human_Joint_Pointer/Regressionnet_highest_pcp.ckpt',\n",
    "              './snapshots/Human_Pose_Estimator/train.ckpt']\n",
    "\n",
    "for i in range(len(saver_path)):\n",
    "    saver_list[i].restore(sess, saver_path[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=cv2.imread('/home/hahnz/test.jpg')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.axis('off')\n",
    "plt.imshow(test_img[:,:,[2,1,0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted = {}\n",
    "Predicted['img'] = test_img.copy()\n",
    "\n",
    "result = Human_Detector.detect([test_img], verbose=1)[0]\n",
    "human_idx = list(result['class_ids']).index(mask_rcnn.class_names.index('person'))\n",
    "\n",
    "###################\n",
    "# Human Detection #\n",
    "###################\n",
    "\n",
    "# Bbox coor\n",
    "padded_coor = tools.etc.pad_bbox_coor(test_img,  result['rois'][human_idx], 1.0)\n",
    "x1,y1,x2,y2 = padded_coor\n",
    "Predicted['bbox'] = padded_coor.copy()\n",
    "\n",
    "# Mask\n",
    "mask = result['masks'][:,:,human_idx].reshape(-1)\n",
    "mask = np.array([255 if detected else 0 for detected in mask]).reshape(test_img.shape[:2])\n",
    "Predicted['mask'] = mask.copy()\n",
    "\n",
    "##########################################\n",
    "# Human Joint Pointing & Pose Estimating #\n",
    "##########################################\n",
    "result = cv2.resize(test_img[x1:x2,y1:y2],(128,128))\n",
    "\n",
    "with All_Graph.as_default():\n",
    "    # Joints\n",
    "    result = tools.etc.normalize_img(result)\n",
    "    result = sess.run(Human_Joint_Pointer.fc_regression,{Human_Joint_Pointer.x:[result],\n",
    "                                                         Human_Joint_Pointer.is_train:False,\n",
    "                                                         Human_Joint_Pointer.keep_prob:1.})\n",
    "    Predicted['joints'] = result[0].squeeze().copy().reshape(-1,2)\n",
    "    \n",
    "    # Activities\n",
    "    result = sess.run(Human_Pose_Estimator.hypothesis, {Human_Pose_Estimator.X:result, \n",
    "                                                        Human_Pose_Estimator.is_train:False,\n",
    "                                                        Human_Pose_Estimator.keep_prob:1.})\n",
    "    Predicted['Activity'] = result.squeeze().copy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "masked = Predicted['img'].copy()\n",
    "a,b,_ = masked.shape\n",
    "for i in range(a):\n",
    "    for j in range(b):\n",
    "        masked[i,j,2] = 100 if Predicted['mask'][i,j] else masked[i,j,2]\n",
    "        \n",
    "x1,y1,x2,y2 = Predicted['bbox'].copy()\n",
    "pred_joints = Predicted['joints'].copy()\n",
    "pred_joints[:,0] = (pred_joints[:,0]/128)*(y2-y1) + Predicted['bbox'][1]\n",
    "pred_joints[:,1] = (pred_joints[:,1]/128)*(x2-x1) + Predicted['bbox'][0]\n",
    "\n",
    "pred_activity = plt.text(y1,x1,'Activity : '+classes[Predicted['Activity']])\n",
    "pred_activity.set_bbox(dict(facecolor='green', alpha=0.5, edgecolor='green'))\n",
    "\n",
    "pred_canonical = tools.pose.convert2canonical(pred_joints[np.newaxis,:,:])[0]\n",
    "masked = tools.etc.markJoints(masked,pred_joints, 0.023)\n",
    "masked = tools.etc.drawSticks(masked,pred_canonical['sticks'], 0.01)\n",
    "\n",
    "masked = cv2.rectangle(masked, (y1,x1), (y2,x2), (0,255,0), 3)\n",
    "plt.axis('off')\n",
    "plt.imshow(masked[:,:,[2,1,0]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
